{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3ba33b-3279-4727-b7f1-e8f0d481c211",
   "metadata": {},
   "source": [
    "# This notebook contains training step and analysis using nmae result..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52550860-12aa-474a-bebe-672f9b63b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, GenericUnivariateSelect\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e1df84-6caf-4898-959a-c7b556fdf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Mean Absolute Error\n",
    "def nmae(y_pred, y_test):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_true = np.mean(np.abs(y_test))\n",
    "    return (mae / mean_true)\n",
    "\n",
    "def normalized_mean_absolute_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Normalized Mean Absolute Error (NMAE).\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): Ground truth (correct) target values.\n",
    "        y_pred (array-like): Estimated target values.\n",
    "\n",
    "    Returns:\n",
    "        float: The Normalized Mean Absolute Error.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"y_true and y_pred must have the same length.\")\n",
    "\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "    # Calculate the range of actual values\n",
    "    y_range = np.max(y_true) - np.min(y_true)\n",
    "\n",
    "    # Avoid division by zero if the range is zero\n",
    "    if y_range == 0:\n",
    "        return 0.0 if mae == 0 else np.inf\n",
    "    else:\n",
    "        nmae = mae / y_range\n",
    "        return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1932041-078e-4f3a-9944-cfa510c65ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7803, 1864)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>container_blkio_device_usage_total_0</th>\n",
       "      <th>container_blkio_device_usage_total_1</th>\n",
       "      <th>container_blkio_device_usage_total_2</th>\n",
       "      <th>container_blkio_device_usage_total_3</th>\n",
       "      <th>container_blkio_device_usage_total_4</th>\n",
       "      <th>container_blkio_device_usage_total_5</th>\n",
       "      <th>container_blkio_device_usage_total_6</th>\n",
       "      <th>container_blkio_device_usage_total_7</th>\n",
       "      <th>container_blkio_device_usage_total_8</th>\n",
       "      <th>...</th>\n",
       "      <th>network_transmit_bytes_per_container_35</th>\n",
       "      <th>network_transmit_bytes_per_container_36</th>\n",
       "      <th>network_transmit_bytes_per_container_37</th>\n",
       "      <th>network_transmit_bytes_per_container_38</th>\n",
       "      <th>network_transmit_bytes_per_container_39</th>\n",
       "      <th>network_transmit_bytes_per_container_40</th>\n",
       "      <th>network_transmit_bytes_per_container_41</th>\n",
       "      <th>network_transmit_bytes_per_container_42</th>\n",
       "      <th>network_transmit_bytes_per_container_43</th>\n",
       "      <th>network_transmit_bytes_per_container_44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1762727858</td>\n",
       "      <td>124854272</td>\n",
       "      <td>543268864</td>\n",
       "      <td>124854272</td>\n",
       "      <td>524222464</td>\n",
       "      <td>23887872</td>\n",
       "      <td>28512849920</td>\n",
       "      <td>23887872</td>\n",
       "      <td>27526397952</td>\n",
       "      <td>126197760</td>\n",
       "      <td>...</td>\n",
       "      <td>12189.931350</td>\n",
       "      <td>0</td>\n",
       "      <td>71774.335259</td>\n",
       "      <td>0</td>\n",
       "      <td>11775.149795</td>\n",
       "      <td>0</td>\n",
       "      <td>95732.086407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1762727859</td>\n",
       "      <td>124854272</td>\n",
       "      <td>543268864</td>\n",
       "      <td>124854272</td>\n",
       "      <td>524222464</td>\n",
       "      <td>23887872</td>\n",
       "      <td>28512858112</td>\n",
       "      <td>23887872</td>\n",
       "      <td>27526397952</td>\n",
       "      <td>126197760</td>\n",
       "      <td>...</td>\n",
       "      <td>12233.595801</td>\n",
       "      <td>0</td>\n",
       "      <td>89717.154189</td>\n",
       "      <td>0</td>\n",
       "      <td>15092.755380</td>\n",
       "      <td>0</td>\n",
       "      <td>95143.605870</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1762727860</td>\n",
       "      <td>124854272</td>\n",
       "      <td>543268864</td>\n",
       "      <td>124854272</td>\n",
       "      <td>524222464</td>\n",
       "      <td>23887872</td>\n",
       "      <td>28512858112</td>\n",
       "      <td>23887872</td>\n",
       "      <td>27526397952</td>\n",
       "      <td>126197760</td>\n",
       "      <td>...</td>\n",
       "      <td>12233.595801</td>\n",
       "      <td>0</td>\n",
       "      <td>69570.165321</td>\n",
       "      <td>0</td>\n",
       "      <td>9959.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>98389.159892</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1762727861</td>\n",
       "      <td>124854272</td>\n",
       "      <td>543268864</td>\n",
       "      <td>124854272</td>\n",
       "      <td>524222464</td>\n",
       "      <td>23887872</td>\n",
       "      <td>28512858112</td>\n",
       "      <td>23887872</td>\n",
       "      <td>27526397952</td>\n",
       "      <td>126197760</td>\n",
       "      <td>...</td>\n",
       "      <td>13788.904300</td>\n",
       "      <td>0</td>\n",
       "      <td>78847.409665</td>\n",
       "      <td>0</td>\n",
       "      <td>14200.456230</td>\n",
       "      <td>0</td>\n",
       "      <td>81172.475424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1762727862</td>\n",
       "      <td>124854272</td>\n",
       "      <td>543268864</td>\n",
       "      <td>124854272</td>\n",
       "      <td>524222464</td>\n",
       "      <td>23887872</td>\n",
       "      <td>28512858112</td>\n",
       "      <td>23887872</td>\n",
       "      <td>27526397952</td>\n",
       "      <td>126197760</td>\n",
       "      <td>...</td>\n",
       "      <td>12768.875193</td>\n",
       "      <td>0</td>\n",
       "      <td>89157.100689</td>\n",
       "      <td>0</td>\n",
       "      <td>10807.993050</td>\n",
       "      <td>0</td>\n",
       "      <td>81172.475424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1864 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  container_blkio_device_usage_total_0  \\\n",
       "0  1762727858                             124854272   \n",
       "1  1762727859                             124854272   \n",
       "2  1762727860                             124854272   \n",
       "3  1762727861                             124854272   \n",
       "4  1762727862                             124854272   \n",
       "\n",
       "   container_blkio_device_usage_total_1  container_blkio_device_usage_total_2  \\\n",
       "0                             543268864                             124854272   \n",
       "1                             543268864                             124854272   \n",
       "2                             543268864                             124854272   \n",
       "3                             543268864                             124854272   \n",
       "4                             543268864                             124854272   \n",
       "\n",
       "   container_blkio_device_usage_total_3  container_blkio_device_usage_total_4  \\\n",
       "0                             524222464                              23887872   \n",
       "1                             524222464                              23887872   \n",
       "2                             524222464                              23887872   \n",
       "3                             524222464                              23887872   \n",
       "4                             524222464                              23887872   \n",
       "\n",
       "   container_blkio_device_usage_total_5  container_blkio_device_usage_total_6  \\\n",
       "0                           28512849920                              23887872   \n",
       "1                           28512858112                              23887872   \n",
       "2                           28512858112                              23887872   \n",
       "3                           28512858112                              23887872   \n",
       "4                           28512858112                              23887872   \n",
       "\n",
       "   container_blkio_device_usage_total_7  container_blkio_device_usage_total_8  \\\n",
       "0                           27526397952                             126197760   \n",
       "1                           27526397952                             126197760   \n",
       "2                           27526397952                             126197760   \n",
       "3                           27526397952                             126197760   \n",
       "4                           27526397952                             126197760   \n",
       "\n",
       "   ...  network_transmit_bytes_per_container_35  \\\n",
       "0  ...                             12189.931350   \n",
       "1  ...                             12233.595801   \n",
       "2  ...                             12233.595801   \n",
       "3  ...                             13788.904300   \n",
       "4  ...                             12768.875193   \n",
       "\n",
       "   network_transmit_bytes_per_container_36  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   network_transmit_bytes_per_container_37  \\\n",
       "0                             71774.335259   \n",
       "1                             89717.154189   \n",
       "2                             69570.165321   \n",
       "3                             78847.409665   \n",
       "4                             89157.100689   \n",
       "\n",
       "   network_transmit_bytes_per_container_38  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   network_transmit_bytes_per_container_39  \\\n",
       "0                             11775.149795   \n",
       "1                             15092.755380   \n",
       "2                              9959.600000   \n",
       "3                             14200.456230   \n",
       "4                             10807.993050   \n",
       "\n",
       "   network_transmit_bytes_per_container_40  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   network_transmit_bytes_per_container_41  \\\n",
       "0                             95732.086407   \n",
       "1                             95143.605870   \n",
       "2                             98389.159892   \n",
       "3                             81172.475424   \n",
       "4                             81172.475424   \n",
       "\n",
       "   network_transmit_bytes_per_container_42  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   network_transmit_bytes_per_container_43  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "\n",
       "   network_transmit_bytes_per_container_44  \n",
       "0                                      0.0  \n",
       "1                                      0.0  \n",
       "2                                      0.0  \n",
       "3                                      0.0  \n",
       "4                                      0.0  \n",
       "\n",
       "[5 rows x 1864 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load write dataset\n",
    "x_ds_c100 = pd.read_csv('datasets/exp60c_2h/t100/prometheus_metrics_wide.csv', low_memory=True).apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "print(x_ds_c100.shape)\n",
    "x_ds_c100.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "130f1eb1-ec08-4c7d-883b-f5305b2ee774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7803, 1864)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>container_blkio_device_usage_total_0</th>\n",
       "      <th>container_blkio_device_usage_total_1</th>\n",
       "      <th>container_blkio_device_usage_total_2</th>\n",
       "      <th>container_blkio_device_usage_total_3</th>\n",
       "      <th>container_blkio_device_usage_total_4</th>\n",
       "      <th>container_blkio_device_usage_total_5</th>\n",
       "      <th>container_blkio_device_usage_total_6</th>\n",
       "      <th>container_blkio_device_usage_total_7</th>\n",
       "      <th>container_blkio_device_usage_total_8</th>\n",
       "      <th>...</th>\n",
       "      <th>network_transmit_bytes_per_container_35</th>\n",
       "      <th>network_transmit_bytes_per_container_36</th>\n",
       "      <th>network_transmit_bytes_per_container_37</th>\n",
       "      <th>network_transmit_bytes_per_container_38</th>\n",
       "      <th>network_transmit_bytes_per_container_39</th>\n",
       "      <th>network_transmit_bytes_per_container_40</th>\n",
       "      <th>network_transmit_bytes_per_container_41</th>\n",
       "      <th>network_transmit_bytes_per_container_42</th>\n",
       "      <th>network_transmit_bytes_per_container_43</th>\n",
       "      <th>network_transmit_bytes_per_container_44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1762718666</td>\n",
       "      <td>124854272</td>\n",
       "      <td>523153408</td>\n",
       "      <td>124854272</td>\n",
       "      <td>504750080</td>\n",
       "      <td>22294528</td>\n",
       "      <td>18027241472</td>\n",
       "      <td>22294528</td>\n",
       "      <td>17279209472</td>\n",
       "      <td>125186048</td>\n",
       "      <td>...</td>\n",
       "      <td>12989.561587</td>\n",
       "      <td>0</td>\n",
       "      <td>91995.257453</td>\n",
       "      <td>0</td>\n",
       "      <td>13904.017857</td>\n",
       "      <td>0</td>\n",
       "      <td>94496.974755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1762718667</td>\n",
       "      <td>124854272</td>\n",
       "      <td>523153408</td>\n",
       "      <td>124854272</td>\n",
       "      <td>504750080</td>\n",
       "      <td>22294528</td>\n",
       "      <td>18027241472</td>\n",
       "      <td>22294528</td>\n",
       "      <td>17279209472</td>\n",
       "      <td>125186048</td>\n",
       "      <td>...</td>\n",
       "      <td>12841.486068</td>\n",
       "      <td>0</td>\n",
       "      <td>93890.433700</td>\n",
       "      <td>0</td>\n",
       "      <td>14582.299227</td>\n",
       "      <td>0</td>\n",
       "      <td>104701.936976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1762718668</td>\n",
       "      <td>124854272</td>\n",
       "      <td>523153408</td>\n",
       "      <td>124854272</td>\n",
       "      <td>504750080</td>\n",
       "      <td>22294528</td>\n",
       "      <td>18027241472</td>\n",
       "      <td>22294528</td>\n",
       "      <td>17279209472</td>\n",
       "      <td>125186048</td>\n",
       "      <td>...</td>\n",
       "      <td>13765.763274</td>\n",
       "      <td>0</td>\n",
       "      <td>74584.501237</td>\n",
       "      <td>0</td>\n",
       "      <td>12281.804734</td>\n",
       "      <td>0</td>\n",
       "      <td>101769.951293</td>\n",
       "      <td>0</td>\n",
       "      <td>12604.872585</td>\n",
       "      <td>430005.600672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1762718669</td>\n",
       "      <td>124854272</td>\n",
       "      <td>523153408</td>\n",
       "      <td>124854272</td>\n",
       "      <td>504750080</td>\n",
       "      <td>22294528</td>\n",
       "      <td>18027241472</td>\n",
       "      <td>22294528</td>\n",
       "      <td>17279209472</td>\n",
       "      <td>125186048</td>\n",
       "      <td>...</td>\n",
       "      <td>11904.655612</td>\n",
       "      <td>0</td>\n",
       "      <td>97924.033523</td>\n",
       "      <td>0</td>\n",
       "      <td>12256.643701</td>\n",
       "      <td>0</td>\n",
       "      <td>94527.552886</td>\n",
       "      <td>0</td>\n",
       "      <td>10402.588398</td>\n",
       "      <td>354876.357754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1762718670</td>\n",
       "      <td>124854272</td>\n",
       "      <td>523153408</td>\n",
       "      <td>124854272</td>\n",
       "      <td>504750080</td>\n",
       "      <td>22294528</td>\n",
       "      <td>18027241472</td>\n",
       "      <td>22294528</td>\n",
       "      <td>17279209472</td>\n",
       "      <td>125186048</td>\n",
       "      <td>...</td>\n",
       "      <td>7763.962677</td>\n",
       "      <td>0</td>\n",
       "      <td>97924.033523</td>\n",
       "      <td>0</td>\n",
       "      <td>10511.954993</td>\n",
       "      <td>0</td>\n",
       "      <td>80978.202448</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1864 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  container_blkio_device_usage_total_0  \\\n",
       "0  1762718666                             124854272   \n",
       "1  1762718667                             124854272   \n",
       "2  1762718668                             124854272   \n",
       "3  1762718669                             124854272   \n",
       "4  1762718670                             124854272   \n",
       "\n",
       "   container_blkio_device_usage_total_1  container_blkio_device_usage_total_2  \\\n",
       "0                             523153408                             124854272   \n",
       "1                             523153408                             124854272   \n",
       "2                             523153408                             124854272   \n",
       "3                             523153408                             124854272   \n",
       "4                             523153408                             124854272   \n",
       "\n",
       "   container_blkio_device_usage_total_3  container_blkio_device_usage_total_4  \\\n",
       "0                             504750080                              22294528   \n",
       "1                             504750080                              22294528   \n",
       "2                             504750080                              22294528   \n",
       "3                             504750080                              22294528   \n",
       "4                             504750080                              22294528   \n",
       "\n",
       "   container_blkio_device_usage_total_5  container_blkio_device_usage_total_6  \\\n",
       "0                           18027241472                              22294528   \n",
       "1                           18027241472                              22294528   \n",
       "2                           18027241472                              22294528   \n",
       "3                           18027241472                              22294528   \n",
       "4                           18027241472                              22294528   \n",
       "\n",
       "   container_blkio_device_usage_total_7  container_blkio_device_usage_total_8  \\\n",
       "0                           17279209472                             125186048   \n",
       "1                           17279209472                             125186048   \n",
       "2                           17279209472                             125186048   \n",
       "3                           17279209472                             125186048   \n",
       "4                           17279209472                             125186048   \n",
       "\n",
       "   ...  network_transmit_bytes_per_container_35  \\\n",
       "0  ...                             12989.561587   \n",
       "1  ...                             12841.486068   \n",
       "2  ...                             13765.763274   \n",
       "3  ...                             11904.655612   \n",
       "4  ...                              7763.962677   \n",
       "\n",
       "   network_transmit_bytes_per_container_36  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   network_transmit_bytes_per_container_37  \\\n",
       "0                             91995.257453   \n",
       "1                             93890.433700   \n",
       "2                             74584.501237   \n",
       "3                             97924.033523   \n",
       "4                             97924.033523   \n",
       "\n",
       "   network_transmit_bytes_per_container_38  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   network_transmit_bytes_per_container_39  \\\n",
       "0                             13904.017857   \n",
       "1                             14582.299227   \n",
       "2                             12281.804734   \n",
       "3                             12256.643701   \n",
       "4                             10511.954993   \n",
       "\n",
       "   network_transmit_bytes_per_container_40  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   network_transmit_bytes_per_container_41  \\\n",
       "0                             94496.974755   \n",
       "1                            104701.936976   \n",
       "2                            101769.951293   \n",
       "3                             94527.552886   \n",
       "4                             80978.202448   \n",
       "\n",
       "   network_transmit_bytes_per_container_42  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   network_transmit_bytes_per_container_43  \\\n",
       "0                                 0.000000   \n",
       "1                                 0.000000   \n",
       "2                             12604.872585   \n",
       "3                             10402.588398   \n",
       "4                                 0.000000   \n",
       "\n",
       "   network_transmit_bytes_per_container_44  \n",
       "0                                 0.000000  \n",
       "1                                 0.000000  \n",
       "2                            430005.600672  \n",
       "3                            354876.357754  \n",
       "4                                 0.000000  \n",
       "\n",
       "[5 rows x 1864 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load write dataset\n",
    "x_ds_c500 = pd.read_csv('datasets/exp60c_2h/t500/prometheus_metrics_wide.csv', low_memory=True).apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "print(x_ds_c500.shape)\n",
    "x_ds_c500.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4487a7-c90b-400e-a1d6-2200927822b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7803, 45)\n",
      "(7803, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_99th_percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   w_99th_percentile\n",
       "0                0.0\n",
       "1                5.0\n",
       "2                5.0\n",
       "3                6.0\n",
       "4                6.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ds_c100 = pd.read_csv('datasets/exp60c_2h/t100/20251109_223738084_w.csv', low_memory=True).apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "print(y_ds_c100.shape)\n",
    "y_ds_c100.head(5)\n",
    "\n",
    "y_ds_c100_w_99th_percentile = y_ds_c100[['w_99th_percentile']].copy()\n",
    "print(y_ds_c100_w_99th_percentile.shape)\n",
    "y_ds_c100_w_99th_percentile.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61052d86-5004-43c0-85b8-e98642707b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7803, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>queries_num</th>\n",
       "      <th>queries_requested</th>\n",
       "      <th>errors_occurred</th>\n",
       "      <th>iter_errors_occurred</th>\n",
       "      <th>average_latency</th>\n",
       "      <th>99_9_latency_percentile</th>\n",
       "      <th>mean_rate</th>\n",
       "      <th>one_minute_rate</th>\n",
       "      <th>five_minute_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>w_min</th>\n",
       "      <th>w_max</th>\n",
       "      <th>w_mean</th>\n",
       "      <th>w_std_dev</th>\n",
       "      <th>w_median</th>\n",
       "      <th>w_75th_percentile</th>\n",
       "      <th>w_95th_percentile</th>\n",
       "      <th>w_98th_percentile</th>\n",
       "      <th>w_99th_percentile</th>\n",
       "      <th>w_99_9th_percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1762718666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1762718667</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>1.236033</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1762718668</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.930949</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.85</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1762718669</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4.208333</td>\n",
       "      <td>0.779028</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.45</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1762718670</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.207441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4.161290</td>\n",
       "      <td>0.687836</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  queries_num  queries_requested  errors_occurred  \\\n",
       "0  1762718666            0                  0                0   \n",
       "1  1762718667            9                  0                0   \n",
       "2  1762718668           16                  0                0   \n",
       "3  1762718669           24                  0                0   \n",
       "4  1762718670           32                  0                0   \n",
       "\n",
       "   iter_errors_occurred  average_latency  99_9_latency_percentile  mean_rate  \\\n",
       "0                     0                0                        0   0.000000   \n",
       "1                     0                4                        1   0.059500   \n",
       "2                     0                4                        1   0.105083   \n",
       "3                     0                4                        1   0.156597   \n",
       "4                     0                4                        1   0.207441   \n",
       "\n",
       "   one_minute_rate  five_minute_rate  ...  w_min  w_max    w_mean  w_std_dev  \\\n",
       "0              0.0               0.0  ...      0      0  0.000000   0.000000   \n",
       "1              0.0               0.0  ...      3      7  4.444444   1.236033   \n",
       "2              0.0               0.0  ...      3      7  4.250000   0.930949   \n",
       "3              0.0               0.0  ...      3      7  4.208333   0.779028   \n",
       "4              0.0               0.0  ...      3      7  4.161290   0.687836   \n",
       "\n",
       "   w_median  w_75th_percentile  w_95th_percentile  w_98th_percentile  \\\n",
       "0       0.0           0.000000               0.00                0.0   \n",
       "1       4.0           4.666667               7.00                7.0   \n",
       "2       4.0           4.000000               6.85                7.0   \n",
       "3       4.0           4.000000               6.45                7.0   \n",
       "4       4.0           4.000000               6.10                7.0   \n",
       "\n",
       "   w_99th_percentile  w_99_9th_percentile  \n",
       "0                0.0                    0  \n",
       "1                7.0                    7  \n",
       "2                7.0                    7  \n",
       "3                7.0                    7  \n",
       "4                7.0                    7  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ds_c500 = pd.read_csv('datasets/exp60c_2h/t500/20251109_200426169_w.csv', low_memory=True).apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "print(y_ds_c500.shape)\n",
    "y_ds_c500.head(5)\n",
    "\n",
    "# y_ds_c500_w_99th_percentile = y_ds_c500[['w_99th_percentile']].copy()\n",
    "# print(y_ds_c500_w_99th_percentile.shape)\n",
    "# y_ds_c500_w_99th_percentile.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c68e18-b384-4431-beef-1126315de8af",
   "metadata": {},
   "source": [
    "# SELECTKBEST FEATURES - 100COLUNAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1c153c-81d0-4fdc-8919-4f7ee4ba508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['network_receive_bytes_per_container_3',\n",
      "       'network_receive_bytes_per_container_5',\n",
      "       'network_receive_bytes_per_container_8',\n",
      "       'network_receive_bytes_per_container_11',\n",
      "       'network_receive_bytes_per_container_12',\n",
      "       'network_transmit_bytes_per_container_3',\n",
      "       'network_transmit_bytes_per_container_5',\n",
      "       'network_transmit_bytes_per_container_8',\n",
      "       'network_transmit_bytes_per_container_11',\n",
      "       'network_transmit_bytes_per_container_12'],\n",
      "      dtype='object')\n",
      "(7803, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johny/environment/repositories/smartness-experiments/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/johny/environment/repositories/smartness-experiments/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:381: RuntimeWarning: invalid value encountered in sqrt\n",
      "  X_norms = np.sqrt(row_norms(X.T, squared=True) - n_samples * X_means**2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network_receive_bytes_per_container_3</th>\n",
       "      <th>network_receive_bytes_per_container_5</th>\n",
       "      <th>network_receive_bytes_per_container_8</th>\n",
       "      <th>network_receive_bytes_per_container_11</th>\n",
       "      <th>network_receive_bytes_per_container_12</th>\n",
       "      <th>network_transmit_bytes_per_container_3</th>\n",
       "      <th>network_transmit_bytes_per_container_5</th>\n",
       "      <th>network_transmit_bytes_per_container_8</th>\n",
       "      <th>network_transmit_bytes_per_container_11</th>\n",
       "      <th>network_transmit_bytes_per_container_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7721.381673</td>\n",
       "      <td>6353.459119</td>\n",
       "      <td>4263.591936</td>\n",
       "      <td>4293.746052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8830.145589</td>\n",
       "      <td>6316.981132</td>\n",
       "      <td>4104.764814</td>\n",
       "      <td>4428.932407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7721.381673</td>\n",
       "      <td>8298.475413</td>\n",
       "      <td>7187.890754</td>\n",
       "      <td>4855.717137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8830.145589</td>\n",
       "      <td>7587.932145</td>\n",
       "      <td>4811.780191</td>\n",
       "      <td>4568.577131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8274.781561</td>\n",
       "      <td>28078.035553</td>\n",
       "      <td>9507.306226</td>\n",
       "      <td>27163.737280</td>\n",
       "      <td>28649.805447</td>\n",
       "      <td>10219.343176</td>\n",
       "      <td>97589.936728</td>\n",
       "      <td>7690.279543</td>\n",
       "      <td>9837.650324</td>\n",
       "      <td>11675.745785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12356.867196</td>\n",
       "      <td>33536.435868</td>\n",
       "      <td>43527.118147</td>\n",
       "      <td>38872.992701</td>\n",
       "      <td>28649.805447</td>\n",
       "      <td>17018.161180</td>\n",
       "      <td>112449.262202</td>\n",
       "      <td>17233.948989</td>\n",
       "      <td>12519.343066</td>\n",
       "      <td>11675.745785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19343.283582</td>\n",
       "      <td>48180.170576</td>\n",
       "      <td>44647.224631</td>\n",
       "      <td>43682.130584</td>\n",
       "      <td>49720.636068</td>\n",
       "      <td>26640.014215</td>\n",
       "      <td>170982.942431</td>\n",
       "      <td>16565.047702</td>\n",
       "      <td>12706.921944</td>\n",
       "      <td>17022.045537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   network_receive_bytes_per_container_3  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                            8274.781561   \n",
       "3                           12356.867196   \n",
       "4                           19343.283582   \n",
       "\n",
       "   network_receive_bytes_per_container_5  \\\n",
       "0                            7721.381673   \n",
       "1                            7721.381673   \n",
       "2                           28078.035553   \n",
       "3                           33536.435868   \n",
       "4                           48180.170576   \n",
       "\n",
       "   network_receive_bytes_per_container_8  \\\n",
       "0                            6353.459119   \n",
       "1                            8298.475413   \n",
       "2                            9507.306226   \n",
       "3                           43527.118147   \n",
       "4                           44647.224631   \n",
       "\n",
       "   network_receive_bytes_per_container_11  \\\n",
       "0                             4263.591936   \n",
       "1                             7187.890754   \n",
       "2                            27163.737280   \n",
       "3                            38872.992701   \n",
       "4                            43682.130584   \n",
       "\n",
       "   network_receive_bytes_per_container_12  \\\n",
       "0                             4293.746052   \n",
       "1                             4855.717137   \n",
       "2                            28649.805447   \n",
       "3                            28649.805447   \n",
       "4                            49720.636068   \n",
       "\n",
       "   network_transmit_bytes_per_container_3  \\\n",
       "0                                0.000000   \n",
       "1                                0.000000   \n",
       "2                            10219.343176   \n",
       "3                            17018.161180   \n",
       "4                            26640.014215   \n",
       "\n",
       "   network_transmit_bytes_per_container_5  \\\n",
       "0                             8830.145589   \n",
       "1                             8830.145589   \n",
       "2                            97589.936728   \n",
       "3                           112449.262202   \n",
       "4                           170982.942431   \n",
       "\n",
       "   network_transmit_bytes_per_container_8  \\\n",
       "0                             6316.981132   \n",
       "1                             7587.932145   \n",
       "2                             7690.279543   \n",
       "3                            17233.948989   \n",
       "4                            16565.047702   \n",
       "\n",
       "   network_transmit_bytes_per_container_11  \\\n",
       "0                              4104.764814   \n",
       "1                              4811.780191   \n",
       "2                              9837.650324   \n",
       "3                             12519.343066   \n",
       "4                             12706.921944   \n",
       "\n",
       "   network_transmit_bytes_per_container_12  \n",
       "0                              4428.932407  \n",
       "1                              4568.577131  \n",
       "2                             11675.745785  \n",
       "3                             11675.745785  \n",
       "4                             17022.045537  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Identify columns to normalize (all except the first)\n",
    "# cols_to_normalize = x_ds_c100.columns[1:]\n",
    "\n",
    "# # Extract the columns to be normalized\n",
    "# df_to_normalize = x_ds_c100[cols_to_normalize]\n",
    "\n",
    "# # Initialize the MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Fit and transform the selected columns\n",
    "# normalized_data = scaler.fit_transform(df_to_normalize)\n",
    "\n",
    "# # Create a new DataFrame with the normalized values\n",
    "# x_ds_c100_norm = pd.DataFrame(normalized_data, columns=cols_to_normalize, index=x_ds_c100.index)\n",
    "\n",
    "# # Concatenate the first column with the normalized DataFrame\n",
    "# x_ds_c100_norm = pd.concat([x_ds_c100.iloc[:, :1], x_ds_c100_norm], axis=1)\n",
    "\n",
    "# # Print the final DataFrame\n",
    "# print(x_ds_c100_norm.shape)\n",
    "\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "x_ds_c100_10f = selector.fit_transform(x_ds_c100, y_ds_c100_w_99th_percentile)\n",
    "\n",
    "# Get a boolean mask of selected features\n",
    "selected_features_mask = selector.get_support()\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = x_ds_c100.columns[selected_features_mask]\n",
    "print(selected_feature_names)\n",
    "\n",
    "x_ds_c100_10f = pd.DataFrame(x_ds_c100_10f, columns=selected_feature_names, index=x_ds_c100.index)\n",
    "print(x_ds_c100_10f.shape)\n",
    "x_ds_c100_10f.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad59e37c-1927-4907-8aaa-bf3965484fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_select_k_best_ds(x, y, k):\n",
    "    selector = SelectKBest(f_regression, k=k)\n",
    "    k_best_ds = selector.fit_transform(x, y)\n",
    "\n",
    "    # Get a boolean mask of selected features\n",
    "    selected_features_mask = selector.get_support()\n",
    "\n",
    "    # Get the names of the selected features\n",
    "    selected_feature_names = x.columns[selected_features_mask]\n",
    "    print(selected_feature_names)\n",
    "\n",
    "    k_best_ds = pd.DataFrame(k_best_ds, columns=selected_feature_names, index=x.index)\n",
    "    print(k_best_ds.shape)\n",
    "    k_best_ds.head(5)\n",
    "    return k_best_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905c5398-a37d-4aa0-ae8b-b08403af1f9a",
   "metadata": {},
   "source": [
    "# Random Forest training using all features and k best features...\n",
    "\n",
    "## train 70%, test 30%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a526639d-e12c-414f-b0fa-72e8e77a5579",
   "metadata": {},
   "source": [
    "## T100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27ab64af-2108-4fb8-958e-0b92ae5061b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand. Forest Training time: 24.167081s\n",
      "Full dataset | 99th_percentile -> Rand. Forest NMAE: 0.09%\n",
      "Rand. Forest Training time: 48.347937s\n",
      "Full dataset | d_99th_percentile -> Rand. Forest NMAE: 2.33%\n",
      "Rand. Forest Training time: 72.590769s\n",
      "Full dataset | w_99th_percentile -> Rand. Forest NMAE: 7.91%\n"
     ]
    }
   ],
   "source": [
    "# Full dataset - wihout normalization...\n",
    "\n",
    "random_forest_model = RandomForestRegressor(n_estimators=240, random_state=42, n_jobs=-1)\n",
    "\n",
    "# using 99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100, y_ds_c100['99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | 99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using d_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100, y_ds_c100['d_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | d_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using w_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100, y_ds_c100['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | w_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2506b4cb-e0e9-42a7-b7f0-a788cc6d195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand. Forest Training time: 30.79498s\n",
      "Full dataset | 99th_percentile -> Rand. Forest NMAE: 0.10%\n",
      "Rand. Forest Training time: 52.514156s\n",
      "Full dataset | d_99th_percentile -> Rand. Forest NMAE: 2.43%\n",
      "Rand. Forest Training time: 73.947967s\n",
      "Full dataset | w_99th_percentile -> Rand. Forest NMAE: 6.83%\n"
     ]
    }
   ],
   "source": [
    "# Full dataset, using pipeline to normalize features and target.\n",
    "\n",
    "# Define the feature pipeline\n",
    "feature_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), # Normalize input features\n",
    "])\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=240, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Combine with target scaling using TransformedTargetRegressor\n",
    "model = TransformedTargetRegressor(\n",
    "    regressor=Pipeline([\n",
    "        ('preprocess', feature_pipeline),\n",
    "        ('model', rf_regressor)\n",
    "    ]),\n",
    "    transformer=MinMaxScaler()  # Normalizes the target y\n",
    ")\n",
    "\n",
    "# using 99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100, y_ds_c100['99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | 99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using d_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100, y_ds_c100['d_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | d_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using w_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100, y_ds_c100['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | w_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c672e19-a2db-40be-b3b7-67195b5123b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand. Forest Training time: 25.202146s\n",
      "Full dataset | 99th_percentile -> Rand. Forest NMAE: 0.09%\n",
      "Rand. Forest Training time: 59.407267s\n",
      "Full dataset | d_99th_percentile -> Rand. Forest NMAE: 3.09%\n",
      "Rand. Forest Training time: 69.290943s\n",
      "Full dataset | w_99th_percentile -> Rand. Forest NMAE: 5.87%\n"
     ]
    }
   ],
   "source": [
    "# Full dataset, using xgboost\n",
    "\n",
    "# 3. Initialize the XGBoost Regressor model\n",
    "# objective='reg:squarederror' is the default for regression, but explicitly setting it is good practice.\n",
    "# n_estimators controls the number of boosting rounds (trees).\n",
    "# random_state for reproducibility.\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, random_state=42)\n",
    "\n",
    "# using 99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100, y_ds_c100['99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | 99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using d_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100, y_ds_c100['d_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | d_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using w_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100, y_ds_c100['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | w_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63b590-c475-4b52-973e-0c08a55e0537",
   "metadata": {},
   "source": [
    "## T500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "048af645-8a79-49e9-bcf2-31f386122771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand. Forest Training time: 44.28541s\n",
      "Full dataset | 99th_percentile -> Rand. Forest NMAE: 0.27%\n",
      "Rand. Forest Training time: 56.095947s\n",
      "Full dataset | d_99th_percentile -> Rand. Forest NMAE: 3.56%\n",
      "Rand. Forest Training time: 93.024478s\n",
      "Full dataset | w_99th_percentile -> Rand. Forest NMAE: 17.66%\n"
     ]
    }
   ],
   "source": [
    "# Full dataset - wihout normalization...\n",
    "\n",
    "random_forest_model = RandomForestRegressor(n_estimators=240, random_state=42, n_jobs=-1)\n",
    "\n",
    "# using 99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500, y_ds_c500['99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | 99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using d_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500, y_ds_c500['d_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | d_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using w_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500, y_ds_c500['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | w_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55a828ce-690f-4988-b978-7a2a81313788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand. Forest Training time: 48.580744s\n",
      "Full dataset | 99th_percentile -> Rand. Forest NMAE: 0.27%\n",
      "Rand. Forest Training time: 59.981796s\n",
      "Full dataset | d_99th_percentile -> Rand. Forest NMAE: 3.61%\n",
      "Rand. Forest Training time: 97.792044s\n",
      "Full dataset | w_99th_percentile -> Rand. Forest NMAE: 17.69%\n"
     ]
    }
   ],
   "source": [
    "# Full dataset, using pipeline to normalize features and target.\n",
    "\n",
    "# Define the feature pipeline\n",
    "feature_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), # Normalize input features\n",
    "])\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=240, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Combine with target scaling using TransformedTargetRegressor\n",
    "model = TransformedTargetRegressor(\n",
    "    regressor=Pipeline([\n",
    "        ('preprocess', feature_pipeline),\n",
    "        ('model', rf_regressor)\n",
    "    ]),\n",
    "    transformer=MinMaxScaler()  # Normalizes the target y\n",
    ")\n",
    "\n",
    "# using 99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500, y_ds_c500['99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | 99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using d_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500, y_ds_c500['d_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | d_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using w_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500, y_ds_c500['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | w_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "080cce95-1c4b-4703-88d0-a11480cdf5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand. Forest Training time: 87.175224s\n",
      "Full dataset | 99th_percentile -> Rand. Forest NMAE: 0.44%\n",
      "Rand. Forest Training time: 117.375869s\n",
      "Full dataset | d_99th_percentile -> Rand. Forest NMAE: 3.74%\n",
      "Rand. Forest Training time: 118.866501s\n",
      "Full dataset | w_99th_percentile -> Rand. Forest NMAE: 16.17%\n"
     ]
    }
   ],
   "source": [
    "# Full dataset, using xgboost\n",
    "\n",
    "# 3. Initialize the XGBoost Regressor model\n",
    "# objective='reg:squarederror' is the default for regression, but explicitly setting it is good practice.\n",
    "# n_estimators controls the number of boosting rounds (trees).\n",
    "# random_state for reproducibility.\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8, random_state=42)\n",
    "\n",
    "# using 99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500, y_ds_c500['99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | 99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using d_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500, y_ds_c500['d_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | d_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using w_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500, y_ds_c500['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print(f'Full dataset | w_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47beee0e-5a92-41cc-b9ab-47fa20a6fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7803, 1864)\n",
      "(7803, 1867)\n",
      "(6981, 1867)\n",
      "(6981, 3)\n",
      "(6981, 1864)\n",
      "Rand. Forest Training time: 14.45166s\n",
      "Full dataset | 99th_percentile -> Rand. Forest NMAE: 0.21%\n",
      "Rand. Forest Training time: 18.403955s\n",
      "Full dataset | d_99th_percentile -> Rand. Forest NMAE: 2.58%\n",
      "Rand. Forest Training time: 27.313033s\n",
      "Full dataset | w_99th_percentile -> Rand. Forest NMAE: 8.80%\n"
     ]
    }
   ],
   "source": [
    "# Dataset removing latencies > 800ms - wihout normalization...\n",
    "# Define the list of columns to be included in the new DataFrame\n",
    "selected_columns = ['timestamp', '99th_percentile', 'd_99th_percentile', 'w_99th_percentile']\n",
    "\n",
    "# Create the new DataFrame by selecting the specified columns\n",
    "y_ds_c500_filtered = y_ds_c500[selected_columns].copy()\n",
    "# print(y_ds_c500_filtered.shape)\n",
    "# y_ds_c500_filtered = y_ds_c500_filtered[(y_ds_c500_filtered['w_99th_percentile'] < 800.00)]\n",
    "# print(y_ds_c500_filtered.shape)\n",
    "\n",
    "# print(\"Min:\", y_ds_c500_filtered['w_99th_percentile'].min())\n",
    "# print(\"Max:\", y_ds_c500_filtered['w_99th_percentile'].max())\n",
    "\n",
    "print(x_ds_c500.shape)\n",
    "# Merge x_ds_c500 with y_ds_c500_filtered to add the 'Target' column\n",
    "x_ds_c500_merged = pd.merge(x_ds_c500, y_ds_c500_filtered, on='timestamp', how='left')\n",
    "print(x_ds_c500_merged.shape)\n",
    "\n",
    "# Filter target columns to less than 800ms\n",
    "x_ds_c500_filtered = x_ds_c500_merged[\n",
    "    (x_ds_c500_merged['99th_percentile'] < 100.00) & \n",
    "    (x_ds_c500_merged['d_99th_percentile'] < 100.00) & \n",
    "    (x_ds_c500_merged['w_99th_percentile'] < 100.00)\n",
    "]\n",
    "print(x_ds_c500_filtered.shape)\n",
    "\n",
    "# Create a new DataFrame with the columns to be dropped\n",
    "columns_to_drop = ['99th_percentile', 'd_99th_percentile', 'w_99th_percentile']\n",
    "y_ds_c500_filtered = x_ds_c500_filtered[columns_to_drop].copy()\n",
    "print(y_ds_c500_filtered.shape)\n",
    "\n",
    "# Drop the columns from the original DataFrame to create a new DataFrame without them\n",
    "x_ds_c500_filtered = x_ds_c500_filtered.drop(columns=columns_to_drop, axis=1)\n",
    "print(x_ds_c500_filtered.shape)\n",
    "\n",
    "random_forest_model = RandomForestRegressor(n_estimators=120, random_state=42, n_jobs=-1)\n",
    "\n",
    "# using 99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500_filtered, y_ds_c500_filtered['99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | 99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using d_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500_filtered, y_ds_c500_filtered['d_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | d_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# using w_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500_filtered, y_ds_c500_filtered['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | w_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7315e1-bc34-48ea-bb00-cf554acd176b",
   "metadata": {},
   "source": [
    "## KBest Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a67a2f7b-4787-4198-ae6c-b75cc94b20f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johny/environment/repositories/smartness-experiments/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:381: RuntimeWarning: invalid value encountered in sqrt\n",
      "  X_norms = np.sqrt(row_norms(X.T, squared=True) - n_samples * X_means**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'container_blkio_device_usage_total_1',\n",
      "       'container_blkio_device_usage_total_3',\n",
      "       'container_blkio_device_usage_total_4',\n",
      "       'container_blkio_device_usage_total_5',\n",
      "       'container_blkio_device_usage_total_6',\n",
      "       'container_blkio_device_usage_total_7',\n",
      "       'container_blkio_device_usage_total_9',\n",
      "       'container_blkio_device_usage_total_11',\n",
      "       'container_blkio_device_usage_total_13',\n",
      "       ...\n",
      "       'network_receive_bytes_per_container_5',\n",
      "       'network_receive_bytes_per_container_6',\n",
      "       'network_receive_bytes_per_container_11',\n",
      "       'network_receive_bytes_per_container_14',\n",
      "       'network_receive_bytes_per_container_38',\n",
      "       'network_transmit_bytes_per_container_3',\n",
      "       'network_transmit_bytes_per_container_5',\n",
      "       'network_transmit_bytes_per_container_6',\n",
      "       'network_transmit_bytes_per_container_11',\n",
      "       'network_transmit_bytes_per_container_14'],\n",
      "      dtype='object', length=500)\n",
      "(7803, 500)\n",
      "(7803, 500)\n",
      "Rand. Forest Training time: 19.294307s\n",
      "Full dataset | 99th_percentile -> Rand. Forest NMAE: 20.08%\n"
     ]
    }
   ],
   "source": [
    "# kbest (100) dataset - without normalization...\n",
    "x_ds_c500_100f = get_select_k_best_ds(x_ds_c500, y_ds_c500['w_99th_percentile'], 500)\n",
    "print(x_ds_c500_100f.shape)\n",
    "\n",
    "random_forest_model = RandomForestRegressor(n_estimators=120, random_state=42, n_jobs=-1)\n",
    "\n",
    "# using 99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c500_100f, y_ds_c500['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | 99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test):.2%}')\n",
    "\n",
    "# # using d_99th_percentile\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_ds_c100_10f, y_ds_c100['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "# time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "# random_forest_model.fit(x_train, y_train)\n",
    "# print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "# predicted = random_forest_model.predict(x_test)\n",
    "# print(f'Full dataset | d_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test)}')\n",
    "\n",
    "# # using w_99th_percentile\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_ds_c100_10f, y_ds_c100['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "# time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "# random_forest_model.fit(x_train, y_train)\n",
    "# print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "# predicted = random_forest_model.predict(x_test)\n",
    "# print(f'Full dataset | w_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13bf3524-71d8-4e9f-a2d9-13adfbf1962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand. Forest Training time: 0.796619s\n",
      "Full dataset | 99th_percentile -> Rand. Forest NMAE: 0.05543340395091246\n",
      "Rand. Forest Training time: 0.562692s\n",
      "Full dataset | d_99th_percentile -> Rand. Forest NMAE: 0.1671126164743545\n",
      "Rand. Forest Training time: 0.671782s\n",
      "Full dataset | w_99th_percentile -> Rand. Forest NMAE: 0.6105355775550029\n"
     ]
    }
   ],
   "source": [
    "# kbest(10) dataset, using pipeline to normalize features and target.\n",
    "\n",
    "# Define the feature pipeline\n",
    "feature_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), # Normalize input features\n",
    "])\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=120, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Combine with target scaling using TransformedTargetRegressor\n",
    "model = TransformedTargetRegressor(\n",
    "    regressor=Pipeline([\n",
    "        ('preprocess', feature_pipeline),\n",
    "        ('model', rf_regressor)\n",
    "    ]),\n",
    "    transformer=MinMaxScaler()  # Normalizes the target y\n",
    ")\n",
    "\n",
    "# using 99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100_10f, y_ds_c100['99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | 99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test)}')\n",
    "\n",
    "# using d_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100_10f, y_ds_c100['d_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | d_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test)}')\n",
    "\n",
    "# using w_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100_10f, y_ds_c100['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | w_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34289026-1bf5-49f2-8a45-6bd86501e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kbest (20) dataset - without normalization...\n",
    "random_forest_model = RandomForestRegressor(n_estimators=120, random_state=42, n_jobs=-1)\n",
    "\n",
    "# using 99th_percentile\n",
    "x_ds_c100_20f = get_select_k_best_ds(x_ds_c100, y_ds_c100[['99th_percentile']].copy(), 20)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100_20f, y_ds_c100['99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | 99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test)}')\n",
    "\n",
    "# using d_99th_percentile\n",
    "x_ds_c100_20f = get_select_k_best_ds(x_ds_c100, y_ds_c100[['d_99th_percentile']].copy(), 20)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100_20f, y_ds_c100['d_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | d_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test)}')\n",
    "\n",
    "# using w_99th_percentile\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ds_c100_10f, y_ds_c100['w_99th_percentile'].to_numpy(), test_size=0.30, random_state=42)\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "print(f'Rand. Forest Training time: {(datetime.datetime.now(tz=datetime.timezone.utc) - time).total_seconds()}s')\n",
    "\n",
    "predicted = random_forest_model.predict(x_test)\n",
    "print(f'Full dataset | w_99th_percentile -> Rand. Forest NMAE: {nmae(predicted, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
